{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Generative AI solution using a RAG Framework: Challenge Lab L400\n",
    "\n",
    "https://partner.cloudskillsboost.google/course_templates/982/labs/463255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --user google-cloud-aiplatform google-cloud-storage firebase-admin\n",
    "!pip install langchain_community\n",
    "!pip install google-cloud-aiplatform\n",
    "!pip install google-cloud-storage\n",
    "!pip install langchain_community\n",
    "!pip install langchain\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import Markdown, display\n",
    "import time\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get project ID\n",
    "PROJECT_ID = ! gcloud config get project\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\"\n",
    "SOURCE_FILE_NAME = \"fpc-manual.pdf\"\n",
    "JSONL_FILE_NAME = \"embeddings.json\"\n",
    "BUCKET_NAME = \"qwiklabs-gcp-00-a99bae2a79d3\"\n",
    "JSONL_FILE_PATH = f\"gs://{BUCKET_NAME}\"\n",
    "EMBEDDING_MODEL_NAME = \"textembedding-gecko@002\"\n",
    "INDEX_DIMENSION = 768\n",
    "INDEX_APPROXIMATE_NEIGHBORS_COUNT = 10\n",
    "INDEX_NAME = \"assessment-index\"\n",
    "DEPLOYED_INDEX_ID = \"assessment_index_deployed\"\n",
    "INDEX_ENDPOINT_NAME = \"assessment-index-endpoint\"\n",
    "INDEX_MACHINE_TYPE = \"n1-standard-2\"\n",
    "# generate an unique id for this session\n",
    "from datetime import datetime\n",
    "UID = datetime.now().strftime(\"%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf\n",
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "import firebase_admin\n",
    "from firebase_admin import firestore\n",
    "from google.cloud import storage\n",
    "# import pandas as pd\n",
    "import json\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@002\")\n",
    "\n",
    "# initialize Firestore\n",
    "# Application Default credentials are automatically created.\n",
    "app = firebase_admin.initialize_app()\n",
    "db = firestore.client()\n",
    "print(f\"Firestore database created successfully.\")\n",
    "\n",
    "# Open the PDF file\n",
    "pdf_file = open(SOURCE_FILE_NAME, 'rb')\n",
    "\n",
    "# Create a PDF reader object\n",
    "pdf_reader = pypdf.PdfReader(pdf_file)\n",
    "\n",
    "# Get the number of pages in the PDF\n",
    "num_pages = len(pdf_reader.pages)\n",
    "print(f\"Read PDF with number of pages: {num_pages}\")\n",
    "\n",
    "with open(JSONL_FILE_NAME, 'w', encoding='utf-8') as f:\n",
    "  # Loop through each page\n",
    "  for page_num in range(num_pages):\n",
    "\n",
    "    # Get the current page\n",
    "    page = pdf_reader.pages[page_num]\n",
    "      \n",
    "    # Extract the text from the page\n",
    "    text = page.extract_text()\n",
    "    \n",
    "    # Write to Firestore\n",
    "    doc_ref = db.collection(\"page_content\").document(str(page_num + 1))\n",
    "    doc_ref.set({'content': text})\n",
    "    print(f\"Document: {str(page_num + 1)} created in Firestore database successfully.\")\n",
    "\n",
    "    # Get the embeddings for the text\n",
    "    raw_embeddings_with_metadata = model.get_embeddings([text])\n",
    "    embeddings = [embedding.values for embedding in raw_embeddings_with_metadata][0]\n",
    "\n",
    "    # construct Panda dataframe\n",
    "    data = {\n",
    "      \"id\": str(page_num + 1),\n",
    "      \"embedding\": embeddings\n",
    "    }\n",
    "\n",
    "    # Write to jsonl file\n",
    "    f.write(json.dumps(data) + \"\\n\")\n",
    "    # df.to_json(f, orient=\"values\", lines=True)\n",
    "\n",
    "    print(f\"Embedding: {str(page_num + 1)} saved in JSONL file successfully.\")\n",
    "\n",
    "# Close the PDF file\n",
    "pdf_file.close()\n",
    "\n",
    "# Create a GCS bucket to store the JSONL file\n",
    "client = storage.Client(project=PROJECT_ID)\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "\n",
    "# Create the bucket if it doesn't exist\n",
    "try:\n",
    "  bucket = client.create_bucket(bucket, location=LOCATION)\n",
    "  print(f\"Bucket {BUCKET_NAME} created successfully.\")\n",
    "except Exception as e:\n",
    "  print(f\"Error creating bucket: {e}\")\n",
    "\n",
    "# Upload the file to the bucket\n",
    "blob = bucket.blob(JSONL_FILE_NAME)\n",
    "blob.upload_from_filename(JSONL_FILE_NAME)\n",
    "print(f\"File {JSONL_FILE_NAME} uploaded to bucket {BUCKET_NAME}.\")\n",
    "\n",
    "# Create a vector index from the JSON-L file\n",
    "index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "  display_name = INDEX_NAME,\n",
    "  contents_delta_uri = JSONL_FILE_PATH,\n",
    "  dimensions = INDEX_DIMENSION,\n",
    "  approximate_neighbors_count = INDEX_APPROXIMATE_NEIGHBORS_COUNT,\n",
    ")\n",
    "\n",
    "# Wait for the index creation to complete\n",
    "index.wait()\n",
    "\n",
    "print(f\"Vector index created: {index.name}\")\n",
    "\n",
    "# Deploy the vector index as an endpoint\n",
    "endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "  display_name = INDEX_ENDPOINT_NAME,\n",
    "  public_endpoint_enabled = True,\n",
    "  description=\"Assessment Index Endpoint\",\n",
    ")\n",
    "\n",
    "endpoint = endpoint.deploy_index(\n",
    "  index = index, \n",
    "  deployed_index_id = DEPLOYED_INDEX_ID,\n",
    ")\n",
    "\n",
    "print(f\"Endpoint deployed: {endpoint.resource_name}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
